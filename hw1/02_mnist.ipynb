{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем первую модель на MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "План на сегодня: пишем первый пайплайн для обучения\n",
    "\n",
    "1. Пытаемся понять, какие компоненты нам нужны для обучения любой модели\n",
    "2. Выясняем, что многое уже есть в Pytorch\n",
    "3. Собираем наш первый скрипт для обучения на датасете MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Разбираемся с данными\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Организуем доступ к данным с `torch.utils.data.Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет в pytorch - это объект класса, в котором реализовано два обязательных метода: `__getitem__(self, index: int)` (получение одиночного примера по индексу) и `__len__(self)` (получение общего количества примеров). Этих методов достаточно, чтобы разбивать датасет на минибатчи  - это работу делает класс `torch.utils.DataLoader` с помощью различных семплеров, с ними мы понакомимся позже"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:45.598694Z",
     "start_time": "2024-09-12T21:00:44.725262Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(42)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x107675690>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:45.604459Z",
     "start_time": "2024-09-12T21:00:45.599802Z"
    }
   },
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, n: int) -> None:\n",
    "        super().__init__()\n",
    "        self.data = torch.arange(n * 3).view((n, 3))\n",
    "        self.labels = torch.randint(0, 5, size=(n,))\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "dataset = MyDataset(n=10)\n",
    "print(dataset[0])\n",
    "print(len(dataset))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0, 1, 2]), tensor(2))\n",
      "10\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итерируемся по датасету:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:45.608356Z",
     "start_time": "2024-09-12T21:00:45.605157Z"
    }
   },
   "source": [
    "dataset = MyDataset(10)\n",
    "for i in range(len(dataset)):\n",
    "    print(dataset[i])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0, 1, 2]), tensor(3))\n",
      "(tensor([3, 4, 5]), tensor(4))\n",
      "(tensor([6, 7, 8]), tensor(0))\n",
      "(tensor([ 9, 10, 11]), tensor(4))\n",
      "(tensor([12, 13, 14]), tensor(1))\n",
      "(tensor([15, 16, 17]), tensor(2))\n",
      "(tensor([18, 19, 20]), tensor(0))\n",
      "(tensor([21, 22, 23]), tensor(0))\n",
      "(tensor([24, 25, 26]), tensor(2))\n",
      "(tensor([27, 28, 29]), tensor(1))\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Пакуем данные в батчи с `torch.utils.data.Dataloader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У `torch.utils.data.Dataloader` много аргументов, на практике чаще всего используются\n",
    "- `dataset` - объект, поддерживающий методы `__getitem__` и `__len__` (вопрос: можно ли передать список? словарь? множество?)\n",
    "- `batch_size` - размер мини-батча\n",
    "- `shuffle` - нужно ли перетасовать индексы перед нарезкой на минибатчи (это всегда стоит делать с обучающими данными, почему?)\n",
    "- `num_workers` - количество процессов, которые будут загружать данные - иногда позволяет ускорить обучение (подумайте, в каком случае?)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:45.674572Z",
     "start_time": "2024-09-12T21:00:45.672325Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "my_loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    # drop_last=\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:45.824050Z",
     "start_time": "2024-09-12T21:00:45.820262Z"
    }
   },
   "source": [
    "for i, batch in enumerate(my_loader):\n",
    "    x, y = batch\n",
    "    if i == 0:\n",
    "        print(x)\n",
    "        print(y)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 25, 26],\n",
      "        [ 6,  7,  8],\n",
      "        [21, 22, 23],\n",
      "        [15, 16, 17]])\n",
      "tensor([2, 0, 0, 2])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Посмотрим на MNIST\n",
    "\n",
    "- какие атрибуты есть у объекта `torchvision.datasets.MNIST`?\n",
    "- как выглядит одно наблюдение?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:46.744219Z",
     "start_time": "2024-09-12T21:00:46.182087Z"
    }
   },
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    \"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),  # что это?\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    \"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:46.748769Z",
     "start_time": "2024-09-12T21:00:46.745644Z"
    }
   },
   "source": [
    "isinstance(train_dataset, Dataset)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:46.752361Z",
     "start_time": "2024-09-12T21:00:46.749682Z"
    }
   },
   "source": [
    "x, y = train_dataset[0]\n",
    "print(x.shape)\n",
    "print(y)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "5\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1 (1 балл)**. Используя `matplotlib`, выведите по одному примеру изображения для всех классов"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:47.451035Z",
     "start_time": "2024-09-12T21:00:46.935713Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "images_per_class = [None] * 10\n",
    "\n",
    "# Проходим по датасету и сохраняем по одному изображению для каждого класса\n",
    "for img, label in train_dataset:\n",
    "    if all(images_per_class):\n",
    "        break\n",
    "    if images_per_class[label] is None:\n",
    "        images_per_class[label] = (img, label)\n",
    "    # Если для всех классов нашли изображения, останавливаем цикл\n",
    "    \n",
    "\n",
    "# Визуализация изображений\n",
    "fig, axs = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, (img, label) in enumerate(images_per_class):\n",
    "    ax = axs[i // 5, i % 5]\n",
    "    ax.imshow(img.squeeze(), cmap='gray')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "### ВАШ ХОД"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 10 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Попробуем получить минибатч:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:47.455067Z",
     "start_time": "2024-09-12T21:00:47.452734Z"
    }
   },
   "source": [
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что возвращает `iter()`?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:47.671663Z",
     "start_time": "2024-09-12T21:00:47.653249Z"
    }
   },
   "source": [
    "batch: tuple[torch.Tensor, torch.Tensor] = next(iter(train_loader))\n",
    "x, y = batch\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Со свёрточными сетями мы познакомимся позже, сейчас же мы будем экспериментировать с обычными полносвязными сетями, но для этого нам нужно будет преобразовать форму батча из `(batch_size, channels, width, height)` в `(batch_size, channels * width * height)`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2 (1 балл)**. Есть несколько способов изменить форму (shape) тензора. Приведите все знаковые вам способы привести батч с изображениями в форму `(batch_size, channels * width * height)`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:48.605238Z",
     "start_time": "2024-09-12T21:00:48.601697Z"
    }
   },
   "source": [
    "batch_size, channels, width, height = x.shape\n",
    "input_dim = channels * width * height\n",
    "x_reshaped = x.reshape(batch_size, input_dim)\n",
    "print(x_reshaped.shape)\n",
    "x_reshaped = x.view(batch_size, input_dim)\n",
    "print(x_reshaped.shape)\n",
    "x_reshaped = x.flatten(start_dim=1)\n",
    "print(x_reshaped.shape)\n",
    "### ВАШ ХОД"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 784])\n",
      "torch.Size([4, 784])\n",
      "torch.Size([4, 784])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ура, с данными вроде разобрались! Теперь разберёмся с моделью"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Реализуем модель с помощью `torch.nn.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Описываем параметры модели и прямой проход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для простоты будем строить небольшую нейронку из двух полносвязных слоёв и `tanh` в качестве функции активации.\n",
    "\n",
    "$\\text{logits} = w_2^T(\\tanh(w_1^T x + b_1)) + b_2$\n",
    "\n",
    "Какие параметры должны быть в линейном слое?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:49.639195Z",
     "start_time": "2024-09-12T21:00:49.634663Z"
    }
   },
   "source": [
    "hidden_dim = 128  # размерность скрытого слоя\n",
    "n_classes = 10\n",
    "\n",
    "# первый слой\n",
    "w1 = torch.randn((input_dim, hidden_dim), requires_grad=True)\n",
    "b1 = torch.randn(hidden_dim, requires_grad=True)\n",
    "\n",
    "# второй слой\n",
    "w2 = torch.randn((hidden_dim, n_classes), requires_grad=True)\n",
    "b2 = torch.randn(n_classes, requires_grad=True)\n",
    "\n",
    "h = x.flatten(1) @ w1 + b1\n",
    "print(h.grad_fn)\n",
    "print(h.shape)\n",
    "\n",
    "# применяем нелинейность перед применением следующего слоя\n",
    "h = h.tanh()\n",
    "\n",
    "h = h @ w2 + b2\n",
    "print(h.grad_fn)\n",
    "print(h.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x15f478a60>\n",
      "torch.Size([4, 128])\n",
      "<AddBackward0 object at 0x15f478a60>\n",
      "torch.Size([4, 10])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:50.967321Z",
     "start_time": "2024-09-12T21:00:50.963801Z"
    }
   },
   "source": [
    "h"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  6.0172,   7.4072, -20.6861,   8.9256,  -5.4395,  -6.3682,   0.0770,\n",
       "           6.8565, -20.1673,  -9.1324],\n",
       "        [ -8.9641, -15.7704, -12.9448,   2.2937, -24.6292, -14.9430,  -0.0394,\n",
       "          -3.6719, -27.6249,  -9.3068],\n",
       "        [ -4.3937,  -0.6097, -28.6687,   7.9132, -10.3090,  -3.1383, -18.3530,\n",
       "           0.4476, -16.2507, -17.0004],\n",
       "        [ -3.8893,   4.6379,  -6.8515,  10.1379,  -4.4632,   4.5285,  -7.7709,\n",
       "          -2.0474, -12.9890,  -1.3313]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из этих выходных данных нам хотелось бы получить вероятностное распределение над возможными классами, то есть нужно как-то нормализовать эти активации, для этого обычно используется функция `softmax`:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:51.512809Z",
     "start_time": "2024-09-12T21:00:51.509264Z"
    }
   },
   "source": [
    "z = torch.randn(10)\n",
    "torch.softmax(z, 0)\n",
    "# zz = torch.exp(z) / torch.exp(z).sum()\n",
    "# zz.sum()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0420, 0.2254, 0.0424, 0.1480, 0.1133, 0.0393, 0.0123, 0.0224, 0.2780,\n",
       "        0.0768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим к нашим данным:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:52.347224Z",
     "start_time": "2024-09-12T21:00:52.343762Z"
    }
   },
   "source": [
    "h.softmax(dim=1)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.8971e-02, 1.5646e-01, 9.8543e-14, 7.1426e-01, 4.1224e-07, 1.6286e-07,\n",
       "         1.0255e-04, 9.0202e-02, 1.6557e-13, 1.0264e-08],\n",
       "        [1.1737e-05, 1.2991e-08, 2.1915e-07, 9.0944e-01, 1.8462e-12, 2.9712e-08,\n",
       "         8.8208e-02, 2.3332e-03, 9.2312e-14, 8.3315e-06],\n",
       "        [4.5170e-06, 1.9870e-04, 1.2952e-16, 9.9921e-01, 1.2186e-08, 1.5851e-05,\n",
       "         3.9118e-12, 5.7198e-04, 3.2019e-11, 1.5130e-11],\n",
       "        [8.0301e-07, 4.0556e-03, 4.1519e-08, 9.9229e-01, 4.5237e-07, 3.6351e-03,\n",
       "         1.6557e-08, 5.0660e-06, 8.9696e-11, 1.0367e-05]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание: классы получились совсем не равновероятны, хотя мы ещё не учили модель. Подумайте, почему так произошло?\n",
    "Подробнее это мы обсудим на следующей практике."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры нашей модели находятся в глобальной области видимости. Решение - спрятать всё внутрь класса-наследника `torch.nn.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Реализуем двуслойный перцептрон как наследник `nn.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3 (1 балл)**. Прочитайте документацию к классам `torch.nn.Module` и `torch.nn.Parameter`. Почему при задании параметров модели не стоит их создавать просто как `torch.tensor(..., requires_grad=True)`?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:54.847317Z",
     "start_time": "2024-09-12T21:00:54.844379Z"
    }
   },
   "source": "Если мы будем использовать torch.tensor(..., requires_grad=True), то тензор не будет зарегистрирован как параметр, и оптимизаторы, такие как torch.optim, не смогут обновлять его значения во время обучения.",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3437587949.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[17], line 1\u001B[0;36m\u001B[0m\n\u001B[0;31m    Если мы будем использовать torch.tensor(..., requires_grad=True), то тензор не будет зарегистрирован как параметр, и оптимизаторы, такие как torch.optim, не смогут обновлять его значения во время обучения.\u001B[0m\n\u001B[0m         ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (1 балл)**. Чтобы сделать наш модуль рабочим, нужно определить два метода: `__init__` и `forward`. Реализуйте метод `forward`, который возвращает логиты, т. е. выход последнего линейного слоя без применения функции активации `softmax`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:55.594541Z",
     "start_time": "2024-09-12T21:00:55.591093Z"
    }
   },
   "source": [
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.w1 = torch.nn.Parameter(torch.randn(input_dim, hidden_dim))\n",
    "        self.b1 = torch.nn.Parameter(torch.randn(hidden_dim))\n",
    "\n",
    "        self.w2 = torch.nn.Parameter(torch.randn(hidden_dim, output_dim))\n",
    "        self.b2 = torch.nn.Parameter(torch.randn(output_dim))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # ВАШ ХОД\n",
    "        x = torch.matmul(x, self.w1) + self.b1\n",
    "        logits = torch.matmul(x, self.w2) + self.b2\n",
    "        return logits"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:00:56.440466Z",
     "start_time": "2024-09-12T21:00:56.162954Z"
    }
   },
   "source": [
    "model = SimpleNet(input_dim, hidden_dim, n_classes)\n",
    "model(x).shape"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (112x28 and 784x128)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m SimpleNet(input_dim, hidden_dim, n_classes)\n\u001B[0;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshape\n",
      "File \u001B[0;32m~/ML_Last_HW/pythonProject3/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ML_Last_HW/pythonProject3/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[18], line 12\u001B[0m, in \u001B[0;36mSimpleNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;66;03m# ВАШ ХОД\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mw1\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mb1\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;66;03m# Применяем второй линейный слой\u001B[39;00m\n\u001B[1;32m     14\u001B[0m     logits \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmatmul(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mw2) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mb2\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (112x28 and 784x128)"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры модели:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "list(model.named_parameters())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вручную обновлять значения многих параметров очень неудобно. К счастью, за нас это сделает оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.01)\n",
    "print(optimizer)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Считаем ошибку и градиенты на одном минибатче"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# получим предсказания и посчитаем ошибку\n",
    "predictions = model.forward(x)\n",
    "loss = torch.nn.functional.cross_entropy(predictions, y)\n",
    "print(loss)\n",
    "# рассчитаем градиенты и обновим параметры\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# не забудем почистить градиенты, мы не хотим их накапливать\n",
    "optimizer.zero_grad()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5 (1 балл)**: Посчитайте значение перекрёстной энтропии самостоятельно по формуле, сверьтесь с результатом выше"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# посчитайте ce_loss на основе значений переменных `predictions` и `y`\n",
    "# ВАШ ХОД\n",
    "ce_loss = ...\n",
    "assert torch.allclose(ce_loss, loss), f\"{ce_loss} != {loss}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Шаг обучения: что мы делаем с каждым минибатчем данных"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def training_step(\n",
    "    batch: tuple[torch.Tensor, torch.Tensor],\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    # прогоняем батч через модель\n",
    "    x, y = batch\n",
    "    predictions = model(x)\n",
    "    # оцениваем значение ошибки\n",
    "    loss = torch.nn.functional.cross_entropy(predictions, y)\n",
    "    # обновляем параметры\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    # возвращаем значение функции ошибки для логирования\n",
    "    return loss, predictions"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тестовых батчей нам не нужны градиенты, поэтому расчёты делаем внутри контекста `torch.no_grad`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def test_step(\n",
    "    batch: tuple[torch.Tensor, torch.Tensor], model: torch.nn.Module\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    x, y = batch\n",
    "    with torch.no_grad():\n",
    "        predictions = model(x)\n",
    "        # оцениваем значение ошибки\n",
    "        loss = torch.nn.functional.cross_entropy(predictions, y)\n",
    "    return loss, predictions"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. А теперь: что мы хотим делать в каждой эпохе?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6 (2 балла)**: Напишите функцию для запуска одной эпохи (обучающей или тестовой), которая итерируется по минибатчам, обрабатывает их и в конце выводит среднюю ошибку и точность классификации. Запустите обучение на 10-15 эпох, добейтесь точности более 92% на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def run_epoch(\n",
    "    is_train: bool,\n",
    "    dataloader: DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    ") -> None:\n",
    "    # ВАШ ХОД\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        ...\n",
    "\n",
    "    epoch_loss = ...\n",
    "    accuracy = ...\n",
    "    print(f\"Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим модель, оптимизатор и загрузчики данных и запустим обучение:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "n_epochs = 15\n",
    "for i in range(n_epochs):\n",
    "    print(f\"Epoch {i} train:\")\n",
    "    run_epoch(True, train_loader, model, optimizer)\n",
    "    print(f\"Epoch {i} test:\")\n",
    "    run_epoch(False, test_loader, model, optimizer)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
