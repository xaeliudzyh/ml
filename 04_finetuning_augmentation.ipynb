{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Свёрточные сети для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T18:04:40.574422Z",
     "start_time": "2024-10-10T18:04:39.578032Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Type, Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1. Skip-connections (2 балла)\n",
    "\n",
    "Постройте архитектуру свёрточной сети, аналогичную архитектуре в примере ниже, но добавьте в неё skip-connections, то есть дополнительные рёбра в вычислительном графе, позволяющие пропускать градиент в более ранние слои напрямую, минуя очередной блок Conv2D + BatchNorm + ReLU:\n",
    "\n",
    "```python\n",
    "def forward(self, x: Tensor) -> Tensor:\n",
    "    x = x + self.block1(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = x + self.block2(x)\n",
    "    x = self.maxpool(x)\n",
    "    ...\n",
    "    x = x.adaptive_maxpool(x).flatten(1)\n",
    "    logits = self.fc(x)\n",
    "    return logits\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша верхнеуровневая архитектура будет выглядеть так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T18:04:41.635331Z",
     "start_time": "2024-10-10T18:04:41.630035Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[nn.Module],\n",
    "        n_classes: int,\n",
    "        hidden_channels: list[int] = [32, 64],\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # входной слой, принимающий изображение с 3-мя каналами\n",
    "        self.in_conv = nn.Conv2d(3, hidden_channels[0], kernel_size=3, stride=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # собираем свёрточные блоки, каждый задаётся кол-вом входных и выходных каналов\n",
    "        blocks = []\n",
    "        for c_in, c_out in zip(hidden_channels[:-1], hidden_channels[1:]):\n",
    "            # добавляем очередной блок\n",
    "            blocks.append(block(c_in, c_out))\n",
    "            # добавляем Max pooling для уменьшения размерности\n",
    "            blocks.append(nn.MaxPool2d(2, 2))\n",
    "\n",
    "        # собираем блоки в единый Sequential модуль для удобства\n",
    "        self.features = nn.Sequential(*blocks)\n",
    "        self.maxpool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        # линейный слой для классификации\n",
    "        self.fc = nn.Linear(hidden_channels[-1], n_classes)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        h = self.features(self.relu(self.in_conv(x)))\n",
    "        logits = self.fc(self.maxpool(h).flatten(1))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовый блок, без residual connections, состоит из двух свёрток и нормализаций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T18:04:42.573218Z",
     "start_time": "2024-10-10T18:04:42.569704Z"
    }
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, inplanes: int, planes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            inplanes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # first conv + bn + nonlinearity\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        # second conv + bn\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        # final nonlinearity\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на результат его применения к тензору:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T18:04:43.538649Z",
     "start_time": "2024-10-10T18:04:43.527961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 32, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BasicBlock(4, 6).forward(torch.randn(3, 4, 32, 32)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно изменить этот блок, добавив в него skip-connection. Теперь в методе `forward` входной тензор `x` пойдёт по двум веткам:\n",
    "1. как в базовом блоке, через наши всёртки и нормализации, до последней нелинейности\n",
    "2. в обход свёрток и нормализаций\n",
    "\n",
    "В конце эти ветки нужно объединить через сумму. Тут есть проблема: в исходном тензоре `x` и обработанном нашим блоком `h(x)` отличается количество каналов (остальные размерности совпадают). То есть нам нужно сравнять количество каналов исходного тензора `inplanes` с количеством выходных каналов `outplanes`.\n",
    "\n",
    "Интуитивно, если рассматривать каждый пиксел входного тензора как вектор размера `inplanes`, в вектор размера `planes` его можно превратить домножением на матрицу размера `inplanes x planes`. Это можно сделать, создав свёрточный слой с размером кернела 1 - он и будет переводить наши пикселы в другую размерность.\n",
    "\n",
    "Не забудьте к сумме каналов применить нелинейность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T18:04:47.452234Z",
     "start_time": "2024-10-10T18:04:47.444332Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inplanes: int, planes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            inplanes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        # добавьте свёртку 1x1 для изменения кол-ва каналов входного тензора\n",
    "        self.downsample = None\n",
    "        self.downsample = nn.Conv2d(inplanes, planes, kernel_size=1, stride=1, bias=False, padding=0)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        # ВАШ ХОД\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "\n",
    "        out += identity\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим размеры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T18:04:48.403107Z",
     "start_time": "2024-10-10T18:04:48.398678Z"
    }
   },
   "outputs": [],
   "source": [
    "assert ResidualBlock(4, 6).forward(torch.randn(3, 4, 32, 32)).shape == torch.Size(\n",
    "    [3, 6, 32, 32]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что модель выдаёт тензор ожидаемого размера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T18:04:50.703717Z",
     "start_time": "2024-10-10T18:04:50.692534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyResNet(ResidualBlock, 7, hidden_channels=[16, 32, 64, 128]).forward(\n",
    "    torch.randn(3, 3, 32, 32)\n",
    ").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем создавать модели разного размера, в том числе достаточно большие и глубокие, чтобы хорошо классифицировать изображения из датасета CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T18:04:51.865659Z",
     "start_time": "2024-10-10T18:04:51.860806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151047"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(\n",
    "    p.numel()\n",
    "    for p in MyResNet(ResidualBlock, 7, hidden_channels=[16, 32, 64, 64]).parameters()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 2. Обучение `MyResNet` с использованием Lightning (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваша задача: добиться 80% точности на валидационной выборке с вашей реализацией `MyResNet`.\n",
    "\n",
    "После окончания обучения используйте метод `Trainer.validate` для вывода ваших метрик с удачного чекпоинта модели.\n",
    "\n",
    "NB: вызывайте `Trainer.validate` везде, где в задании требуется достичь какой-то точности\n",
    "\n",
    "\n",
    "Советы:\n",
    "- По умолчанию Lightning сохраняет только последний чекпоинт, так что вам может потребоваться `lightning.callbacks.ModelCheckpoint`, чтобы сохранять лучший чекпоинт в процессе обучения.\n",
    "\n",
    "- Используйте tensorboard, чтобы следить за динамикой обучения. Если заметите переобучение - подключайте регуляризацию. Большая модель с регуляризацией обычно лучше маленькой модели без неё.\n",
    "\n",
    "- Чтобы добиться нужной точности, ваша модель должна быть достаточно глубокой, ориентируйтесь на 4-5 блоков. Если необходимо, подключайте регуляризацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T20:53:41.784828Z",
     "start_time": "2024-10-10T20:50:05.141959Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type     | Params | Mode \n",
      "-------------------------------------------\n",
      "0 | model | MyResNet | 151 K  | train\n",
      "-------------------------------------------\n",
      "151 K     Trainable params\n",
      "0         Non-trainable params\n",
      "151 K     Total params\n",
      "0.605     Total estimated model params size (MB)\n",
      "30        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215a1becab7f4b1f8c55119b4f411d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 391: 'val_acc' reached 0.65130 (best 0.65130), saving model to 'tb_logs/MyResNet/version_12/checkpoints/best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 782: 'val_acc' reached 0.73690 (best 0.73690), saving model to 'tb_logs/MyResNet/version_12/checkpoints/best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 1173: 'val_acc' reached 0.74170 (best 0.74170), saving model to 'tb_logs/MyResNet/version_12/checkpoints/best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 1564: 'val_acc' reached 0.76230 (best 0.76230), saving model to 'tb_logs/MyResNet/version_12/checkpoints/best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1955: 'val_acc' reached 0.77840 (best 0.77840), saving model to 'tb_logs/MyResNet/version_12/checkpoints/best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 2346: 'val_acc' reached 0.81540 (best 0.81540), saving model to 'tb_logs/MyResNet/version_12/checkpoints/best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 2737: 'val_acc' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 3128: 'val_acc' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 3519: 'val_acc' reached 0.82020 (best 0.82020), saving model to 'tb_logs/MyResNet/version_12/checkpoints/best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 3910: 'val_acc' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 4301: 'val_acc' reached 0.83750 (best 0.83750), saving model to 'tb_logs/MyResNet/version_12/checkpoints/best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 4692: 'val_acc' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 5083: 'val_acc' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 5474: 'val_acc' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 5865: 'val_acc' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 6256: 'val_acc' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 6647: 'val_acc' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 7038: 'val_acc' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 7429: 'val_acc' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 7820: 'val_acc' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at tb_logs/MyResNet/version_12/checkpoints/best-checkpoint.ckpt\n",
      "Loaded model weights from the checkpoint at tb_logs/MyResNet/version_12/checkpoints/best-checkpoint.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0833f21a61b94c53a4e051fc22623b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         val_acc            0.8374999761581421\n",
      "        val_loss             0.512255847454071\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.512255847454071, 'val_acc': 0.8374999761581421}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.utilities.types import EVAL_DATALOADERS, TRAIN_DATALOADERS\n",
    "from torchvision import datasets, transforms\n",
    "from typing import Callable, Any\n",
    "from PIL.Image import Image\n",
    "from torch import Tensor, nn\n",
    "\n",
    "\n",
    "\n",
    "class Datamodule(L.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size: int,\n",
    "        transform: Callable[[Image], Tensor] = transforms.ToTensor(),\n",
    "        num_workers: int = 0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        # в этом методе можно сделать предварительную работу, например\n",
    "        # скачать данные, сделать тяжёлый препроцессинг\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage: str) -> None:\n",
    "        # аргумент `stage` будет приходить из модуля обучения Trainer\n",
    "        # на стадии обучения (fit) нам нужны оба датасета\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset = datasets.CIFAR10(\n",
    "                \"data\",\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=self.transform,\n",
    "            )\n",
    "            self.val_dataset = datasets.CIFAR10(\n",
    "                \"data\",\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=transforms.ToTensor(),\n",
    "            )\n",
    "        # на стадии валидации (validate) - только тестовый\n",
    "        elif stage == \"validate\":\n",
    "            self.val_dataset = datasets.CIFAR10(\n",
    "                \"data\",\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=transforms.ToTensor(),\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        # есть ещё стадии `test` и `predict`, но они нам не понадобятся\n",
    "\n",
    "    def train_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "    \n",
    "\n",
    "datamodule = Datamodule(batch_size=128)\n",
    "class LitModel(L.LightningModule):\n",
    "    def __init__(self, model: nn.Module, learning_rate: float = 1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['model'])\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch: tuple[Tensor, Tensor], batch_idx: int) -> Tensor:\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: tuple[Tensor, Tensor], batch_idx: int) -> None:\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "    def configure_optimizers(self) -> dict[str, Any]:\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "            optimizer, milestones=[5, 10, 15], gamma=0.5\n",
    "        )\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "\n",
    "model = MyResNet(\n",
    "    ResidualBlock,\n",
    "    n_classes=10,\n",
    "    hidden_channels=[16, 32, 64, 64],\n",
    ")\n",
    "\n",
    "lit_model = LitModel(model)\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"MyResNet\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_top_k=1,\n",
    "    filename='best-checkpoint',\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator='auto',\n",
    "    devices='auto',\n",
    "    max_epochs=20,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    #limit_train_batches=999,\n",
    "    #limit_val_batches=999,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    datamodule=datamodule,\n",
    ")\n",
    "trainer.validate(\n",
    "    model=lit_model,\n",
    "    datamodule=datamodule,\n",
    "    ckpt_path=checkpoint_callback.best_model_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 3. Добавление аугментаций (1 балл + 2 балла за точность на валидации более 85%)\n",
    "\n",
    "Добавьте к обучающему датасету аугментации - случайные трансформации входных данных. Для этого можно использовать `torchvision.transforms` и `albumentations`.\n",
    "\n",
    "С `torchvision.transforms` совсем просто: вам нужно будет при создании `Datamodule` из практики по `lightning` указать вместо\n",
    "\n",
    "```python\n",
    "transform = transforms.ToTensor()\n",
    "```\n",
    "композицию трансформаций:\n",
    "\n",
    "```python\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # случайное зеркальное отражение\n",
    "    ...\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В пакете `albumentations` аугментаций значительно больше:\n",
    "\n",
    "![albumentations](https://albumentations.ai/assets/img/custom/top_image.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 4. Использование предобученной модели (4 балла)\n",
    "\n",
    "Теперь мы научимся использовать модели, обученные на других задачах\n",
    "\n",
    "Ваша задача: добиться 90% точности на тестовой выборке CIFAR-10. Постарайтесь уложиться модель с ~5 млн параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `torchvision.models` есть много реализованных архитектур, размером которых можно удобно управлять. Например, ниже можно создать крошечную версию модели `MobileNetV2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46322"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import MobileNetV2\n",
    "\n",
    "mobilenet = MobileNetV2(\n",
    "    num_classes=10,\n",
    "    width_mult=0.4,\n",
    "    inverted_residual_setting=[\n",
    "        # t, c, n, s\n",
    "        [1, 16, 1, 1],\n",
    "        [3, 24, 2, 2],\n",
    "        [3, 32, 3, 2],\n",
    "    ],\n",
    "    dropout=0.2,\n",
    ")\n",
    "\n",
    "sum([param.numel() for param in mobilenet.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но кроме архитектуры модели, мы также можем скачать веса, полученные при обучении на каком-то датасете. Например, для нашей задачи можно использовать предобучение на самом известном датасете для классификации изображений - ImageNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5288548"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models.efficientnet import EfficientNet_B0_Weights, efficientnet_b0\n",
    "\n",
    "# создаём EfficientNet с весами, полученными на ImageNet\n",
    "weights = EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "efficientnet = efficientnet_b0(weights=weights)\n",
    "sum([param.numel() for param in efficientnet.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Указание 1.** С использованием модели в исходном виде есть проблема: в ImageNet 1000 классов, а у нас только 10. Поэтому в предобученной модели нужно будет полностью заменить последний линейный слой, который даёт распределение вероятностей классов. Это можно сделать уже в готовом объекте модели, переназначив атрибут.\n",
    "\n",
    "Подсказка: в `efficientnet_b0` линейный слой находится в атрибуте `classifier` \n",
    "\n",
    "\n",
    "**Указание 2.** Все слои, кроме нескольких последних (может быть, только последнего) мы можем заморозить, то есть сделать значения параметров в них неизменными. Это позволит и сохранить способность модели выделять полезные низкоуровневые признаки (она научилась этому на ImageNet), и существенно ускорить дообучение.\n",
    "\n",
    "\n",
    "Чтобы заморозить параметры, нужно всего лишь отключить для них расчёт градиентов. Вернитесь к первой практике, чтобы вспомнить, как это можно сделать. Нам подойдёт самый простой способ с `.requires_grad`.\n",
    "\n",
    "Подсказка: в `efficientnet_b0` свёрточные слои находятся в атрибуте `features` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Указание 3.** Предобученные модели на ImageNet ожидают специальным образом трансформированные изображения:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[256]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BICUBIC\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому эти трансформации нужно будет передать в датамодуль (как мы делали с аугментациями)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАШ ХОД: Обучите модель и выведите результат метода validate на удачном чекпоинте"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
