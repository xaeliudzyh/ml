{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 трансформер для перевода с немецкого на английский"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегодня вы поработаете над настоящей задачей NLP и попробуете обучить трансформер переводить короткие предложения с английского на немецкий.\n",
    "\n",
    "Токенизацию и блоки трансформера писать не придётся — будем пользоваться библиотекой `transformers`.\n",
    "\n",
    "Наши задачи:\n",
    "- Познакомиться с наиболее популярным методом токенизации текстов — byte pair encoding\n",
    "- Научиться пользоваться токенизатором из `transformers`\n",
    "- Подготовить даннные\n",
    "- Обучить готовую архитектуру T5-small под нашу задачу\n",
    "- Исследовать разные стратегии декодирования с помощью обученной модели"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:36:15.036968Z",
     "start_time": "2024-11-17T02:36:09.586270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install datasets transformers[sentencepiece]\n",
    "!pip install sentencepiece"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: transformers[sentencepiece]\r\n",
      "Collecting sentencepiece\r\n",
      "  Obtaining dependency information for sentencepiece from https://files.pythonhosted.org/packages/79/91/b54a528e0789cd7986341ed3909bec56365c3b672daef8b10aa4098238f0/sentencepiece-0.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading sentencepiece-0.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.7 kB)\r\n",
      "Downloading sentencepiece-0.2.0-cp39-cp39-macosx_11_0_arm64.whl (1.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m1.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: sentencepiece\r\n",
      "Successfully installed sentencepiece-0.2.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:38:46.740171Z",
     "start_time": "2024-11-17T02:38:43.529226Z"
    }
   },
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "from typing import cast\n",
    "\n",
    "import lightning as L\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "from datasets import load_dataset, load_from_disk"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsagoll/ML_Last_HW/pythonProject3/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:39:03.138421Z",
     "start_time": "2024-11-17T02:39:03.134139Z"
    }
   },
   "source": [
    "torch.manual_seed(42)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x103f29770>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Готовим данные"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:39:19.296040Z",
     "start_time": "2024-11-17T02:39:06.246814Z"
    }
   },
   "source": [
    "train_dataset = load_dataset(\"bentrevett/multi30k\", split=\"train\")\n",
    "test_dataset = load_dataset(\"bentrevett/multi30k\", split=\"test\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:21:24.173306Z",
     "start_time": "2024-11-17T02:21:24.166652Z"
    }
   },
   "source": [
    "train_dataset[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:42:08.771215Z",
     "start_time": "2024-11-17T02:42:07.716216Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def length_histogram(dataset, ax, bins=20) -> None:\n",
    "    en_lengths = []\n",
    "    de_lengths = []\n",
    "    for sample in dataset:\n",
    "        en_lengths.append(len(sample[\"en\"].split(\" \")))\n",
    "        de_lengths.append(len(sample[\"de\"].split(\" \")))\n",
    "\n",
    "    ax.hist(en_lengths, alpha=0.5, bins=bins, label=\"en\")\n",
    "    ax.hist(de_lengths, alpha=0.5, bins=bins, label=\"de\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "length_histogram(train_dataset, axes[0])\n",
    "length_histogram(test_dataset, axes[1])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим только сравнительно короткие предложения, чтобы можно было чему-то научиться за короткое время"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:42:12.127851Z",
     "start_time": "2024-11-17T02:42:11.361689Z"
    }
   },
   "source": [
    "maxlen = 8\n",
    "\n",
    "\n",
    "def filter_dataset(dataset, maxlen: int) -> list[dict[str, str]]:\n",
    "    return [\n",
    "        dataset[i]\n",
    "        for i in range(len(dataset))\n",
    "        if len(dataset[i][\"en\"].split(\" \")) <= maxlen\n",
    "    ]\n",
    "\n",
    "\n",
    "train_filtered = filter_dataset(train_dataset, maxlen)\n",
    "test_filtered = filter_dataset(test_dataset, maxlen)\n",
    "\n",
    "print(len(train_filtered), len(test_filtered))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5144 174\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Токенизация: byte-pair encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение:\n",
    "\n",
    "Начинаем со словаря, состоящего из отдельных символов (начальные токены).\n",
    "На каждом шаге:\n",
    "1. Оцениваем частоту всех пар токенов внутри слов, находим самую частую\n",
    "2. Добавляем её в список токенов и в таблицу слияний\n",
    "3. Останавливаемся, когда достигаем максимального размера словаря\n",
    "\n",
    "\n",
    "Применение:\n",
    "\n",
    "1. Разбиваем текст на символы\n",
    "2. Находим первое возможное слияние в таблице и применяем его\n",
    "3. Останавливаемся, когда дальнейшие слияния невозможны\n",
    "\n",
    "<img src=\"https://lena-voita.github.io/resources/lectures/seq2seq/bpe/build_merge_table.gif\" style=\"background:white\" height=\"300\"/>\n",
    "<img src=\"https://lena-voita.github.io/resources/lectures/seq2seq/bpe/bpe_apply.gif\" style=\"background:white\" height=\"300\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализаций много, мы будем использовать токенизатор  из библиотеки `transformers`, где помимо самого подготовленного токенизатора (`sentencepiece.SentencePieceProcessor`) много полезных методов для кодирования и декодирования.\n",
    "\n",
    "Добавим при создании новый токен, который будет указывать на начало перевода"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:42:27.703209Z",
     "start_time": "2024-11-17T02:42:15.358730Z"
    }
   },
   "source": [
    "tokenizer: T5Tokenizer = T5Tokenizer.from_pretrained(\n",
    "    \"t5-small\", padding_size=\"right\", bos_token=\"</b>\", legacy=False\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8060c37c56aa4b0cb1abdcd1016c2fd6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "164a05d0dd5746bfb1e3551f1b1e3be0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa9484ed115b4439ac2fee9bc83fa1f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:42:32.316326Z",
     "start_time": "2024-11-17T02:42:32.313841Z"
    }
   },
   "source": [
    "print(\"Размер словаря: \", len(tokenizer))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря:  32101\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на примеры токенов, в них встречаются и целые слова из разных языков, и числительные, и знаки препинания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('▁showed', 3217),\n",
       " ('▁Saint', 2788),\n",
       " ('▁Sonic', 20419),\n",
       " ('▁zahlreiche', 9878),\n",
       " ('popular', 27302),\n",
       " ('▁mathematical', 18913),\n",
       " ('likewise', 15340),\n",
       " ('▁si', 108),\n",
       " ('▁Damage', 26135),\n",
       " ('▁choses', 12344)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.choices(list(tokenizer.get_vocab().items()), k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизатор в работе: кодирование и декодирование предложений на немецком и английском:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:42:40.867226Z",
     "start_time": "2024-11-17T02:42:40.858107Z"
    }
   },
   "source": [
    "encoded_german = tokenizer.encode(train_dataset[0][\"de\"])\n",
    "encoded_english = tokenizer.encode(train_dataset[0][\"en\"])\n",
    "print(encoded_german)\n",
    "print(tokenizer.decode(encoded_german))\n",
    "print(encoded_english)\n",
    "print(tokenizer.decode(encoded_english))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11280, 16815, 7838, 15, 16282, 436, 256, 8671, 35, 16, 74, 13271, 2221, 49, 21162, 3992, 5, 1]\n",
      "Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.</s>\n",
      "[2759, 1021, 6, 1945, 5069, 7, 33, 1067, 1084, 186, 3, 30271, 5, 1]\n",
      "Two young, White males are outside near many bushes.</s>\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Об упаковке в батчи можно больше не беспокоиться — токенизатор умеет обрабатывать сразу пачку примеров"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:42:43.893684Z",
     "start_time": "2024-11-17T02:42:43.887370Z"
    }
   },
   "source": [
    "batch = [train_dataset[i][\"en\"] for i in range(4)]\n",
    "\n",
    "encoded_batch = tokenizer.batch_encode_plus(\n",
    "    batch, padding=\"longest\", return_tensors=\"pt\"\n",
    ")\n",
    "print(encoded_batch[\"input_ids\"].shape)\n",
    "print(encoded_batch.keys())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 19])\n",
      "dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возвращается два значения: `input_ids` — это наши токены, а `attention_mask` — это тензор, равный по размеру батчу токенов, где на месте `pad_token` стоят нули, в остальных позициях — единицы. Это нам понадобится потом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А ещё можно кодировать сразу входные и выходные данные:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:42:47.207186Z",
     "start_time": "2024-11-17T02:42:47.201244Z"
    }
   },
   "source": [
    "inputs = [train_dataset[i][\"en\"] + tokenizer.bos_token for i in range(4)]\n",
    "targets = [train_dataset[i][\"de\"] for i in range(4)]\n",
    "\n",
    "encoded_batch = tokenizer(\n",
    "    inputs, text_target=targets, padding=\"longest\", return_tensors=\"pt\"\n",
    ")\n",
    "print(encoded_batch.keys())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем это в `collate_fn` для сборки батчей:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:42:49.385603Z",
     "start_time": "2024-11-17T02:42:49.380754Z"
    }
   },
   "source": [
    "def collate_fn(\n",
    "    tokenizer: T5Tokenizer, batch: list[tuple[str, str]]\n",
    ") -> tuple[Tensor, Tensor]:\n",
    "    prompt = tokenizer.bos_token\n",
    "    inputs, targets = zip(*[(pair[\"de\"], prompt + pair[\"en\"]) for pair in batch])\n",
    "    encoded_batch = tokenizer(\n",
    "        inputs, text_target=targets, padding=\"longest\", return_tensors=\"pt\"\n",
    "    )\n",
    "    return encoded_batch"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:42:49.876362Z",
     "start_time": "2024-11-17T02:42:49.872840Z"
    }
   },
   "source": [
    "batch = [train_dataset[i] for i in range(4)]\n",
    "encoded_batch = collate_fn(tokenizer, batch)\n",
    "print(encoded_batch.keys())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:42:50.569950Z",
     "start_time": "2024-11-17T02:42:50.567115Z"
    }
   },
   "source": [
    "print(encoded_batch[\"input_ids\"].shape)\n",
    "print(encoded_batch[\"attention_mask\"].shape)\n",
    "print(encoded_batch[\"labels\"].shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 22])\n",
      "torch.Size([4, 22])\n",
      "torch.Size([4, 20])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всё готово для получения минибатчей из датасетов:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:42:51.831608Z",
     "start_time": "2024-11-17T02:42:51.828047Z"
    }
   },
   "source": [
    "train_loader = DataLoader(\n",
    "    train_filtered,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda batch: collate_fn(tokenizer, batch),\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_filtered,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda batch: collate_fn(tokenizer, batch),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1 (3 балла). DataModule\n",
    "\n",
    "Реализуйте подкласс `lightning.LightningDataModule` для работы с обучающим и тестовым датасетами"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:42:55.164983Z",
     "start_time": "2024-11-17T02:42:55.154233Z"
    }
   },
   "source": [
    "from lightning.pytorch.utilities.types import EVAL_DATALOADERS, TRAIN_DATALOADERS\n",
    "\n",
    "\n",
    "class Multi30kDataset(L.LightningDataModule):\n",
    "    train_dataset: Dataset\n",
    "    test_dataset: Dataset\n",
    "    tokenizer: T5Tokenizer\n",
    "    def __init__(self, maxlen: int = 0, batch_size: int = 32) -> None:\n",
    "        super().__init__()\n",
    "        self.maxlen = maxlen\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(\n",
    "            \"t5-small\", padding_size=\"right\", bos_token=\"</b>\", legacy=False\n",
    "        )\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        # Download datasets; this is only called on one process in distributed settings\n",
    "        load_dataset(\"bentrevett/multi30k\", split=\"train\")\n",
    "        load_dataset(\"bentrevett/multi30k\", split=\"test\")\n",
    "\n",
    "    def setup(self, stage: str = None) -> None:\n",
    "        # Load datasets; called on every process in distributed settings\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.train_dataset = load_dataset(\"bentrevett/multi30k\", split=\"train\")\n",
    "            self.test_dataset = load_dataset(\"bentrevett/multi30k\", split=\"test\")\n",
    "\n",
    "            if self.maxlen > 0:\n",
    "                self.train_dataset = self.filter_dataset(self.train_dataset, self.maxlen)\n",
    "                self.test_dataset = self.filter_dataset(self.test_dataset, self.maxlen)\n",
    "\n",
    "    def filter_dataset(self, dataset, maxlen: int) -> list[dict[str, str]]:\n",
    "        return [\n",
    "            dataset[i]\n",
    "            for i in range(len(dataset))\n",
    "            if len(dataset[i][\"en\"].split(\" \")) <= maxlen\n",
    "        ]\n",
    "\n",
    "    def collate_fn(self, batch: list[dict[str, str]]) -> dict[str, Tensor]:\n",
    "        prompt = self.tokenizer.bos_token\n",
    "        inputs, targets = zip(*[(pair[\"de\"], prompt + pair[\"en\"]) for pair in batch])\n",
    "        encoded_batch = self.tokenizer(\n",
    "            inputs, text_target=targets, padding=\"longest\", return_tensors=\"pt\"\n",
    "        )\n",
    "        return encoded_batch\n",
    "\n",
    "    def train_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=self.collate_fn,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=self.collate_fn,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return self.val_dataloader()"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:42:57.173032Z",
     "start_time": "2024-11-17T02:42:56.488382Z"
    }
   },
   "source": [
    "multi30k = Multi30kDataset(maxlen=8, batch_size=12)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 2 (6 баллов). Обучение T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paper: https://arxiv.org/abs/1910.10683"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите `t5-small` на наших данных, длительность обучения — на ваше усмотрение. В [документации](https://huggingface.co/docs/transformers/model_doc/t5) вы найдёте примеры использования, которые помогут вам разобраться в интерфейсе модели."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T03:12:41.483750Z",
     "start_time": "2024-11-17T03:09:17.708171Z"
    }
   },
   "source": [
    "t5 = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7669a82ff9745969802e53abb999fc9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74b78ee2a9494d90b2f4e76bd373f650"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15696eead8da46b6a7260a4ee835606c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обернём в `LightningModule`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T03:16:22.666925Z",
     "start_time": "2024-11-17T03:16:22.639991Z"
    }
   },
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT, OptimizerLRScheduler\n",
    "\n",
    "\n",
    "class Seq2Seq(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        lr: float = 0.001,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.lr = lr\n",
    "\n",
    "    def training_step(self, batch: dict[str, Tensor], batch_idx: int) -> STEP_OUTPUT:\n",
    "        outputs = self.model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            labels=batch[\"labels\"],\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        self.log(\"loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:04:03.049149Z",
     "start_time": "2024-11-17T04:01:46.858008Z"
    }
   },
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "#logger = TensorBoardLogger(\"lightning_logs\", name=\"t5_translation\")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    max_epochs=50,\n",
    "    limit_train_batches=10,\n",
    "   # logger=logger, \n",
    ")\n",
    "seq2seq = Seq2Seq(t5, multi30k.tokenizer, lr=0.001)\n",
    "trainer.fit(model=seq2seq, datamodule=multi30k)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type                       | Params | Mode\n",
      "------------------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M | eval\n",
      "------------------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "277       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96c26e96caf743edbdad10d6148820ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 3 (3 балла). Генерация перевода\n",
    "\n",
    "Сгенерируйте перевод для одного батча из тестового датасета (используйте метод `t5.generate()`), используя разные стратегии декодирования:\n",
    "- *greedy decoding*\n",
    "- *multinomial sampling*\n",
    "- *beam-search multinomial sampling*\n",
    "\n",
    "Эти стратегии (а также другие стратегии декодирования) можно задавать через `transformers.GenerationConfig`, который можно передать в метод `.generate()` нашей модели.\n",
    "Выберите параметры, которые, на ваш взгляд, работают лучше всего."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:21:06.820532Z",
     "start_time": "2024-11-17T04:21:06.812728Z"
    }
   },
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "greedy_conf = GenerationConfig(\n",
    "    max_new_tokens=40,\n",
    "    do_sample=False,\n",
    "    num_beams=1,     \n",
    ")\n",
    "\n",
    "# Multinomial Sampling с изменёнными параметрами\n",
    "sampling_conf = GenerationConfig(\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,        \n",
    "    temperature=0.6,       \n",
    "    top_p=0.85,             \n",
    "    num_beams=1,           \n",
    "    no_repeat_ngram_size=2, \n",
    ")\n",
    "beam_sampling_conf = GenerationConfig(\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,           \n",
    "    temperature=0.7,        \n",
    "    top_p=0.9,              \n",
    "    num_beams=8,             \n",
    "    length_penalty=1.2,      \n",
    "    no_repeat_ngram_size=3,   \n",
    "    early_stopping=True,     \n",
    ")"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:21:09.929807Z",
     "start_time": "2024-11-17T04:21:07.278330Z"
    }
   },
   "source": [
    "batch = next(iter(multi30k.test_dataloader()))\n",
    "\n",
    "try:\n",
    "    greedy_preds = t5.generate(batch[\"input_ids\"], generation_config=greedy_conf)\n",
    "    sampling_preds = t5.generate(batch[\"input_ids\"], generation_config=sampling_conf)\n",
    "    beam_sampling_preds = t5.generate(batch[\"input_ids\"], generation_config=beam_sampling_conf)\n",
    "except TypeError as e:\n",
    "    print(\"Ошибка при генерации:\", e)\n",
    "    print(\"Проверьте, что batch является словарём с нужными ключами.\")\n",
    "    raise\n",
    "\n",
    "inputs = multi30k.tokenizer.batch_decode(batch[\"input_ids\"], skip_special_tokens=True)\n",
    "labels = batch[\"labels\"].clone()\n",
    "labels[labels == -100] = multi30k.tokenizer.pad_token_id  \n",
    "targets = multi30k.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "greedy_outputs = multi30k.tokenizer.batch_decode(greedy_preds, skip_special_tokens=True)\n",
    "sampling_outputs = multi30k.tokenizer.batch_decode(sampling_preds, skip_special_tokens=True)\n",
    "beam_sampling_outputs = multi30k.tokenizer.batch_decode(beam_sampling_preds, skip_special_tokens=True)\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    print(f\"Input {i+1}: {inputs[i]}\")\n",
    "    print(f\"Target {i+1}: {targets[i]}\")\n",
    "    print(f\"Greedy Output {i+1}: {greedy_outputs[i]}\")\n",
    "    print(f\"Sampling Output {i+1}: {sampling_outputs[i]}\")\n",
    "    print(f\"Beam Sampling Output {i+1}: {beam_sampling_outputs[i]}\")\n",
    "    print(\"-\" * 80)\n",
    "# декодируем входы, правильный и сгенерированный перевод с помощью токенизатора и выводим\n",
    "..."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 1: Leute Reparieren das Dach eines Hauses.\n",
      "Target 1: People are fixing the roof of a house.\n",
      "Greedy Output 1: People are fixing a roof of a house.\n",
      "Sampling Output 1: People are fixing a roof of ten people.\n",
      "Beam Sampling Output 1: People are fixing a roof of a house.\n",
      "--------------------------------------------------------------------------------\n",
      "Input 2: Ein Typ arbeitet an einem Gebäude.\n",
      "Target 2: A guy works on a building.\n",
      "Greedy Output 2: A guy working on a building.\n",
      "Sampling Output 2: A guy working on a building.\n",
      "Beam Sampling Output 2: A guy working on a building.\n",
      "--------------------------------------------------------------------------------\n",
      "Input 3: Drei Leute sitzen in einer Höhle.\n",
      "Target 3: Three people sit in a cave.\n",
      "Greedy Output 3: Thre people are sitting in a höhle.\n",
      "Sampling Output 3: Thre people are sitting in a höhle.\n",
      "Beam Sampling Output 3: Thre people are sitting in a cave.\n",
      "--------------------------------------------------------------------------------\n",
      "Input 4: Leute, die vor einem Gebäude stehen.\n",
      "Target 4: People standing outside of a building.\n",
      "Greedy Output 4: People standing outside of a building.\n",
      "Sampling Output 4: People standing outside of a building.\n",
      "Beam Sampling Output 4: People standing outside of a building.\n",
      "--------------------------------------------------------------------------------\n",
      "Input 5: Ein Mann schneidet ste von Bäumen.\n",
      "Target 5: A man cutting branches of trees.\n",
      "Greedy Output 5: A man cutting trees.\n",
      "Sampling Output 5: A man cutting a tree tree.\n",
      "Beam Sampling Output 5: A man chopping from trees.\n",
      "--------------------------------------------------------------------------------\n",
      "Input 6: Frauen, die traditionelle Kleidung tragen, spielen das Leben Einheimischer nach.\n",
      "Target 6: Women, wearing traditional clothing, are reenacting native life.\n",
      "Greedy Output 6: Women wearing traditional clothing playing home.\n",
      "Sampling Output 6: Women wearing traditional clothing playing home.\n",
      "Beam Sampling Output 6: Women wearing traditional clothing playing home.\n",
      "--------------------------------------------------------------------------------\n",
      "Input 7: Ein Kind planscht im Wasser.\n",
      "Target 7: A child is splashing in the water\n",
      "Greedy Output 7: A child splashing in the water.\n",
      "Sampling Output 7: A child splashing in the water.\n",
      "Beam Sampling Output 7: A child splashing in the water.\n",
      "--------------------------------------------------------------------------------\n",
      "Input 8: Eine schöne Frau spielt auf einer Harfe.\n",
      "Target 8: A pretty woman plays a harpsichord.\n",
      "Greedy Output 8: A beautiful woman is playing on a harp.\n",
      "Sampling Output 8: A beautiful woman playing on a harp.\n",
      "Beam Sampling Output 8: A beautiful woman plays on a harp.\n",
      "--------------------------------------------------------------------------------\n",
      "Input 9: Die junge Dame sieht auf die Pizza.\n",
      "Target 9: The young lady is looking at the pizza.\n",
      "Greedy Output 9: The young lady is looking at the pizza.\n",
      "Sampling Output 9: The young lady is looking on the pizza.\n",
      "Beam Sampling Output 9: The young lady is looking at the pizza.\n",
      "--------------------------------------------------------------------------------\n",
      "Input 10: Leute sitzen in einem Zug.\n",
      "Target 10: People sit inside a train.\n",
      "Greedy Output 10: People are sitting in a train.\n",
      "Sampling Output 10: People are sitting in a train.\n",
      "Beam Sampling Output 10: People are sitting in a train.\n",
      "--------------------------------------------------------------------------------\n",
      "Input 11: Ein kleines Kind kocht mit einer anderen Person.\n",
      "Target 11: A toddler is cooking with another person.\n",
      "Greedy Output 11: A small child cooking with another person.\n",
      "Sampling Output 11: A small child cooking with another person.\n",
      "Beam Sampling Output 11: A small child cooking with another person.\n",
      "--------------------------------------------------------------------------------\n",
      "Input 12: Ein Mann bereitet am Herd Essen zu.\n",
      "Target 12: A man cooking food on the stove.\n",
      "Greedy Output 12: A man is preparing food for the crop.\n",
      "Sampling Output 12: A man is preparing food to eat.\n",
      "Beam Sampling Output 12: A man is preparing food to eat.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-mcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
